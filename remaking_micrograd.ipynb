{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start off, I want to get acquainted with derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import a few libraries to help visualize and work through the arithmetic. We will also use numpy to generate random numbers later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets say that we have a function f(x) and\n",
    "# we want to see how important each of the\n",
    "# variables are for the final output of the\n",
    "# function.\n",
    "# We can slightly increment one of the variables\n",
    "# and compare the output of the function call\n",
    "# before and after we nudged the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4*x**2 + 3*x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1824df779d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(start=-5, stop=5, step=0.25)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.995999999997565"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 0.001\n",
    "x = -2.0\n",
    "(f(x+h) - f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the slope between the two points:\n",
    "f(x) and f(x+h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These slopes can be used to determine how variables affect the outcome of a mathematical expression. We are ultimately taking the derivative of a function with multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "\n",
    "h = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nudged function output:  3.997\n",
      "original function output: 4.0\n",
      "slope:  -3.0000000000001137\n"
     ]
    }
   ],
   "source": [
    "original = a * b + c\n",
    "a += h\n",
    "nudged = a * b + c\n",
    "\n",
    "print(\"nudged function output: \", nudged)\n",
    "print(\"original function output:\", original)\n",
    "print(\"slope: \", (nudged - original) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nudged function output:  3.999001\n",
      "original function output: 3.997\n",
      "slope:  2.0009999999999195\n"
     ]
    }
   ],
   "source": [
    "original = a * b + c\n",
    "b += h\n",
    "nudged = a * b + c\n",
    "\n",
    "print(\"nudged function output: \", nudged)\n",
    "print(\"original function output:\", original)\n",
    "print(\"slope: \", (nudged - original) / h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These slope outputs make sense because when taking the partial derivative with respect to a or b, in this instance, the equations result in their multiplicative counterpart:  \n",
    "$d/da(a * b + c)$  &emsp; &emsp; &emsp; &emsp;                          $d/db(a * b + c)$  \n",
    "$= d/da(ab) + d/da(c)$  &emsp;                                          $= d/db(ab) + d/db(c)$  \n",
    "$= a^0 * b + 0$  &emsp;  &emsp; &emsp; &emsp; &ensp; &ensp;             $= a * b^0 + 0$  \n",
    "$= b$  &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &ensp;   $= a$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when differentiating with respect to c, a constant, it will increase at a rate of 1 since it has no effect on the other variables other than the value being added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nudged function output:  4.000000999999999\n",
      "original function output: 3.999001\n",
      "slope:  0.9999999999994458\n"
     ]
    }
   ],
   "source": [
    "original = a * b + c\n",
    "c += h\n",
    "nudged = a * b + c\n",
    "\n",
    "print(\"nudged function output: \", nudged)\n",
    "print(\"original function output:\", original)\n",
    "print(\"slope: \", (nudged - original) / h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to micrograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building out micrograd, we are going to need to make a Value object. We need a Value object to keep track of the children of the expression when doing backpropagation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    def __repr__(self):\n",
    "        return(f\"Value(val={self.val})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=4.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 4.0\n",
    "Value(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to be able to add or multiply two value objects together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    def __init__(self, val, _children=(), _op=''):\n",
    "        self.val = val\n",
    "        # prev is stored as a set, as opposed  \n",
    "        # to a tuple, for efficiency.\n",
    "        self.prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.grad=0\n",
    "    def __repr__(self):\n",
    "        return(f\"Value(val={self.val})\") \n",
    "    def __add__(self, other):\n",
    "        out = Value(self.val+other.val, (self, other), '+')\n",
    "        return out\n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.val*other.val, (self, other), '*')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b:  Value(val=5.0)\n",
      "a*b:  Value(val=6.0)\n",
      "{Value(val=2.0), Value(val=3.0)}\n",
      "operator:  +\n"
     ]
    }
   ],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(3.0)\n",
    "print(\"a+b: \", a+b)\n",
    "print(\"a*b: \", a*b)\n",
    "\n",
    "x = a+b\n",
    "print(x.prev)\n",
    "print(\"operator: \", x._op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to add backpropagation (partial derivatives), and an activation function to our Value object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    def __init__(self, val, _children=(), _op=''):\n",
    "        self.val = val\n",
    "        # prev is stored as a set, as opposed  \n",
    "        # to a tuple, for efficiency.\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.grad = 0\n",
    "        self._backward = lambda:None    # initialized to an empty lambda function\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(f\"Value(val={self.val})\") \n",
    "    \n",
    "    def __add__(self, other):\n",
    "        out = Value(self.val+other.val, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad     # Note: the gradients have to accumulate (+=) to avoid issues \n",
    "            other.grad += 1.0 * self.grad   #       where a variable is used in an expression more than once.\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.val*other.val, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.grad += other.val * out.grad\n",
    "            other.grad += self.val * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        x = self.val\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "        def _backward():\n",
    "            self.grad = (1 - t**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        x = self.val\n",
    "        out = Value(math.exp(x) / 1 + (math.exp(x)), (self, ), 'sigmoid')\n",
    "        def _backward():\n",
    "            self.grad = math.exp(x) / ((math.exp(x) + 1) ** 2)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Value(2.0)\n",
    "x2 = Value(0.0)\n",
    "w1 = Value(-3.0)\n",
    "w2 = Value(1.0)\n",
    "x1w1 = x1 * w1\n",
    "x2w2 = x2 * w2\n",
    "b = Value(6.8813735870195432)\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "n = x1w1x2w2 + b\n",
    "o = n.tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0\n",
    "o._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.grad\n",
    "n._backward()\n",
    "x1w1x2w2._backward()\n",
    "x1w1._backward()\n",
    "x2w2._backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:  -1.4999999999999996\n",
      "x2:  0.4999999999999999\n",
      "w1:  0.9999999999999998\n",
      "w2:  0.0\n",
      "x1w1:  0.4999999999999999\n",
      "x1w2:  0.4999999999999999\n",
      "x1w1x2w2:  0.4999999999999999\n",
      "n:  0.4999999999999999\n",
      "o:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"x1: \", x1.grad)\n",
    "print(\"x2: \", x2.grad)\n",
    "print(\"w1: \", w1.grad)\n",
    "print(\"w2: \", w2.grad)\n",
    "print(\"x1w1: \", x1w1.grad)\n",
    "print(\"x1w2: \", x2w2.grad)\n",
    "print(\"x1w1x2w2: \", x1w1x2w2.grad)\n",
    "print(\"n: \", n.grad)\n",
    "print(\"o: \", o.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build a topological graph of the whole structure and call _backward() on each component starting at the output (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topological_graph = []\n",
    "visited = set()\n",
    "def build_topological_graph(node):\n",
    "    if node not in visited:\n",
    "        visited.add(node)\n",
    "        for child in node._prev:\n",
    "            build_topological_graph(child)\n",
    "        topological_graph.append(node)\n",
    "\n",
    "build_topological_graph(o)\n",
    "\n",
    "for node in reversed(topological_graph):\n",
    "    node._backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Value(2.0)\n",
    "x2 = Value(0.0)\n",
    "w1 = Value(-3.0)\n",
    "w2 = Value(1.0)\n",
    "x1w1 = x1 * w1\n",
    "x2w2 = x2 * w2\n",
    "b = Value(6.8813735870195432)\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "n = x1w1x2w2 + b\n",
    "o = n.tanh()\n",
    "o.grad = 1.0\n",
    "\n",
    "topological_graph = []\n",
    "visited = set()\n",
    "def build_topological_graph(node):\n",
    "    if node not in visited:\n",
    "        visited.add(node)\n",
    "        for child in node._prev:\n",
    "            build_topological_graph(child)\n",
    "        topological_graph.append(node)\n",
    "\n",
    "build_topological_graph(o)\n",
    "\n",
    "for node in reversed(topological_graph):\n",
    "    node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:  -1.4999999999999996\n",
      "x2:  0.4999999999999999\n",
      "w1:  0.9999999999999998\n",
      "w2:  0.0\n",
      "x1w1:  0.4999999999999999\n",
      "x1w2:  0.4999999999999999\n",
      "x1w1x2w2:  0.4999999999999999\n",
      "n:  0.4999999999999999\n",
      "o:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"x1: \", x1.grad)\n",
    "print(\"x2: \", x2.grad)\n",
    "print(\"w1: \", w1.grad)\n",
    "print(\"w2: \", w2.grad)\n",
    "print(\"x1w1: \", x1w1.grad)\n",
    "print(\"x1w2: \", x2w2.grad)\n",
    "print(\"x1w1x2w2: \", x1w1x2w2.grad)\n",
    "print(\"n: \", n.grad)\n",
    "print(\"o: \", o.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It calculates the gradiants automatically!\n",
    "Now let's make some changes to our Value class.\n",
    "We want to add the backward pass as a callable function on a Value object. We also want to add some more arithmetic functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    def __init__(self, val, _children=(), _op=''):\n",
    "        self.val = val\n",
    "        # prev is stored as a set, as opposed  \n",
    "        # to a tuple, for efficiency.\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.grad = 0\n",
    "        self._backward = lambda:None    # initialized to an empty lambda function\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(f\"Value(val={self.val})\") \n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "\n",
    "        out = Value(self.val+other.val, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad     # Note: the gradients have to accumulate (+=) to avoid issues \n",
    "            other.grad += 1.0 * out.grad   #       where a variable is used in an expression more than once.\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + -(other)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "\n",
    "    # rmul allows non-value types to multiply with value types.\n",
    "    # e.g. x = Value(5.0), 3 * x gets routed as x*3 thanks to this function.\n",
    "    def __rmul__(self, other):\n",
    "        return self*other\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "\n",
    "        out = Value(self.val*other.val, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.grad += other.val * out.grad\n",
    "            other.grad += self.val * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self * (other ** -1)     # x / a = x * 1/a\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"int or float only\"\n",
    "        out = Value(self.val ** other, (self, ), f\"**{other}\")\n",
    "        def _backward():\n",
    "            self.grad += other * self.val**(other-1) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def exp(self):\n",
    "        x = self.val\n",
    "        out = Value(math.exp(x), (self, ), 'exp')\n",
    "        def _backward():\n",
    "            self.grad += out.val * out.grad  # local derivative of e^x is just e^x\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.val\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, (self, ), 'tanh')\n",
    "        def _backward():\n",
    "            self.grad = (1 - t**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        x = self.val\n",
    "        out = Value(math.exp(x) / 1 + (math.exp(x)), (self, ), 'sigmoid')\n",
    "        def _backward():\n",
    "            self.grad = math.exp(x) / ((math.exp(x) + 1) ** 2)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        topological_graph = []\n",
    "        visited = set()\n",
    "        def build_topological_graph(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                for child in node._prev:\n",
    "                    build_topological_graph(child)\n",
    "                topological_graph.append(node)\n",
    "\n",
    "        build_topological_graph(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topological_graph):\n",
    "            node._backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(val=-2.0)\n",
      "Value(val=32.0)\n",
      "Value(val=2.0)\n",
      "Value(val=3.0)\n",
      "Value(val=8.0)\n",
      "Value(val=4.0)\n",
      "Value(val=6.0)\n"
     ]
    }
   ],
   "source": [
    "x = Value(2.0)\n",
    "y = Value(4.0)\n",
    "print(x-y)\n",
    "print(x**5)\n",
    "print(y/x)\n",
    "print(x+1)\n",
    "print(y*2)\n",
    "print(2*x)\n",
    "print(2+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to now start building the classes that represent different components of a neural network starting with a neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        # weights\n",
    "        self.weights = []\n",
    "        for _ in range(num_inputs):\n",
    "            self.weights.append(Value(random.uniform(-1,1)))\n",
    "        # bias\n",
    "        self.bias = Value(random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        act = sum(wi*xi for wi, xi in zip(self.weights, x)) + self.bias\n",
    "        out = act.tanh()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=-0.0908700982057028)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2.0, 3.0]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        self.neurons = []\n",
    "        for _ in range(num_outputs):\n",
    "            self.neurons.append(Neuron(num_inputs))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron(x))\n",
    "\n",
    "        # if there is only one output, just return the Value instead of an array\n",
    "        if len(outputs) == 1:\n",
    "            return outputs[0]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(val=0.3355564687527405), Value(val=-0.8437562493709622), Value(val=-0.2855862836780614)]\n"
     ]
    }
   ],
   "source": [
    "x = [2.0, 3.0]\n",
    "n = Layer(2, 3)\n",
    "print(n(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        ls = [num_inputs] + num_outputs     # each layer is an array of inputs\n",
    "        self.layers = []\n",
    "        for i in range(len(num_outputs)):\n",
    "            self.layers.append(Layer(ls[i], ls[i+1]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=-0.0653794261985003)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1.5, -2.0, 3.0]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)    # forward pass of the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to tweak the parameters of the neural network, I am going to add a function to the neuron, layer, and mlp class that will get the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        # weights\n",
    "        self.weights = []\n",
    "        for _ in range(num_inputs):\n",
    "            self.weights.append(Value(random.uniform(-1,1)))\n",
    "        # bias\n",
    "        self.bias = Value(random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        act = sum(wi*xi for wi, xi in zip(self.weights, x)) + self.bias\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.weights + [self.bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        self.neurons = []\n",
    "        for _ in range(num_outputs):\n",
    "            self.neurons.append(Neuron(num_inputs))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron(x))\n",
    "\n",
    "        # if there is only one output, just return the Value instead of an array\n",
    "        if len(outputs) == 1:\n",
    "            return outputs[0]\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for neuron in self.neurons:\n",
    "            ps = neuron.get_params()\n",
    "            params.extend(ps)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        ls = [num_inputs] + num_outputs     # each layer is an array of inputs\n",
    "        self.layers = []\n",
    "        for i in range(len(num_outputs)):\n",
    "            self.layers.append(Layer(ls[i], ls[i+1]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            ls = layer.get_params()\n",
    "            params.extend(ls)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new added get_params functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=-0.47551317485475936)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1.5, -2.0, 3.0]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)    # forward pass of the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(val=0.42213035516965625),\n",
       " Value(val=0.41481410015858966),\n",
       " Value(val=0.574771227825537),\n",
       " Value(val=-0.3903282952742162),\n",
       " Value(val=0.9087588893457827),\n",
       " Value(val=0.14667360489495618),\n",
       " Value(val=0.4611335437433153),\n",
       " Value(val=-0.591862990318071),\n",
       " Value(val=-0.4274345768986807),\n",
       " Value(val=-0.7304095369749863),\n",
       " Value(val=0.12917306511791837),\n",
       " Value(val=-0.8938273787642321),\n",
       " Value(val=-0.6394577204438139),\n",
       " Value(val=-0.6334058531667832),\n",
       " Value(val=-0.3538648132726885),\n",
       " Value(val=0.6257951274951805),\n",
       " Value(val=-0.974433554308503),\n",
       " Value(val=0.0054406410351106604),\n",
       " Value(val=0.8755513386934644),\n",
       " Value(val=-0.978102243210802),\n",
       " Value(val=0.23027786513249304),\n",
       " Value(val=0.13080747145247607),\n",
       " Value(val=0.3401183625435853),\n",
       " Value(val=0.6148841655733446),\n",
       " Value(val=-0.05180733809215621),\n",
       " Value(val=-0.1274473665800251),\n",
       " Value(val=-0.9101178788048867),\n",
       " Value(val=0.5985058410457196),\n",
       " Value(val=-0.12200776626253718),\n",
       " Value(val=-0.41162841855726606),\n",
       " Value(val=-0.35398267217161417),\n",
       " Value(val=0.34779889157514665),\n",
       " Value(val=0.12998207600144163),\n",
       " Value(val=0.35865855204236174),\n",
       " Value(val=0.7209244999986006),\n",
       " Value(val=-0.4385080627039737),\n",
       " Value(val=0.3319215376268514),\n",
       " Value(val=-0.6087983658327754),\n",
       " Value(val=0.3587010014988059),\n",
       " Value(val=-0.8801652697539275),\n",
       " Value(val=-0.02749580733571033)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with a simple binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "train_y = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=4.833790677508481)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [n(x) for x in train_X]\n",
    "loss = sum((pred - ground_truth)**2 for ground_truth, pred in zip(train_y, y_pred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the current loss without training. I am now going to show one step of training before automating the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also want to define a learning rate, \n",
    "# which is the rate at which we will adjust the val.\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to ultimately reduce the loss coming from our neural network.\n",
    "By running the next two cells, it will reset the gradients to 0.0, conduct a backward pass, update the parameters, and then a forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero grad\n",
    "for parameter in n.get_params():\n",
    "    parameter.grad = 0.0\n",
    "\n",
    "# backwards pass\n",
    "loss.backward()\n",
    "\n",
    "# adjust parameters based on generated gradients. If the gradient\n",
    "# is negative, then increasing the val will bring the loss down.\n",
    "for parameter in n.get_params():\n",
    "    parameter.val += -LEARNING_RATE * parameter.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(val=4.75000216915292)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [n(x) for x in train_X]\n",
    "loss = sum((pred - ground_truth)**2 for ground_truth, pred in zip(train_y, y_pred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to automate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "train_y = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    # forward pass\n",
    "    y_pred = [n(x) for x in train_X]\n",
    "    loss = sum((pred - ground_truth)**2 for ground_truth, pred in zip(train_y, y_pred))\n",
    "\n",
    "    # backward pass with zero grad\n",
    "    for parameter in n.get_params():\n",
    "        parameter.grad = 0.0\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    for parameter in n.get_params():\n",
    "        parameter.val += -LEARNING_RATE * parameter.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.026264524529209722\n",
      "ground truth:  [1.0, -1.0, -1.0, 1.0]\n",
      "predictions:  [Value(val=0.9376983092789885), Value(val=-0.9650651899992887), Value(val=-0.8928168565647037), Value(val=0.901641692389224)]\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: \", loss.val)\n",
    "print(\"ground truth: \", train_y)\n",
    "print(\"predictions: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the predictions are very close to the ground truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
